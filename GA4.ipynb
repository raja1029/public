{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "r6VXGJX8WLLh",
        "outputId": "572ba217-df56-467a-f57c-168ac2fa6d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-analytics-data\n",
            "  Downloading google_analytics_data-0.14.2-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2 in /usr/local/lib/python3.8/dist-packages (from google-analytics-data) (2.8.2)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.8/dist-packages (from google-analytics-data) (3.19.6)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.8/dist-packages (from google-analytics-data) (1.22.1)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-analytics-data) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-analytics-data) (2.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-analytics-data) (1.57.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-analytics-data) (1.51.1)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-analytics-data) (1.48.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-analytics-data) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-analytics-data) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-analytics-data) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-analytics-data) (5.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-analytics-data) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-analytics-data) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-analytics-data) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-analytics-data) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.33.2->google-analytics-data) (3.0.4)\n",
            "Installing collected packages: google-analytics-data\n",
            "Successfully installed google-analytics-data-0.14.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# install the google analytics package for python\n",
        "!pip install google-analytics-data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# provide the path to your json file which has configuration details for google analytics 4 in place of service_account_file_path\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = service_account_file_path"
      ],
      "metadata": {
        "id": "Hz22kNkhb0P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.analytics.data_v1beta import BetaAnalyticsDataClient\n",
        "from google.analytics.data_v1beta.types import DateRange\n",
        "from google.analytics.data_v1beta.types import Dimension\n",
        "from google.analytics.data_v1beta.types import Metric\n",
        "from google.analytics.data_v1beta.types import RunReportRequest\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Oqq2vNInb25O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def sample_run_report(property_id, export_path):\n",
        "\n",
        "    client = BetaAnalyticsDataClient()\n",
        "\n",
        "    request = RunReportRequest(\n",
        "        property=f\"properties/{property_id}\",\n",
        "        dimensions=[Dimension(name=\"city\")],  # dimensions and metrics need to be changed based on your report\n",
        "        metrics=[Metric(name=\"activeUsers\")],\n",
        "        date_ranges=[DateRange(start_date='7daysAgo', end_date=\"today\")],\n",
        "    )\n",
        "    response = client.run_report(request)\n",
        "\n",
        "    output = []\n",
        "    print(\"Report result:\")\n",
        "    for row in response.rows:\n",
        "      output.append({row.dimension_values[0].value, row.metric_values[0].value})\n",
        "    df = pd.DataFrame(output)\n",
        "    df.to_csv(export_path)\n",
        "  \n"
      ],
      "metadata": {
        "id": "v_jByJmObeWV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_run_report(PROPERTY_ID, \"export.csv\")\n",
        "df = pd.read_csv(\"export.csv\")\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "cFuZnEU8biDt",
        "outputId": "2d1a9725-1648-4b9f-a1f2-2957faf31571"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5bc012c2bfbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_run_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROPERTY_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"export.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"export.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PROPERTY_ID' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# once export.csv is generated, it can be used to send it to big query using big query commands at gcp shell."
      ],
      "metadata": {
        "id": "4JfL-fy3btgz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}


from collections import defaultdict
from collections import deque
from typing import Dict
from typing import List
from typing import Tuple

from sql_graph.parsing.primitives import Coordinates
from sql_graph.parsing.primitives.settings import MAX_PIXELS_PER_GRID_COLUMN
from sql_graph.parsing.primitives.settings import TABLE_X_SPACING
from sql_graph.parsing.primitives.settings import TABLE_Y_SPACING
from sql_graph.typing import TCoordinates
from sql_graph.typing import TTable


class TopologicalLayout:
  """
  Simple layout algorithm positions tables in topological order.

  Vertical positioning is semi-random.

  Attributes:
    _table_order (Dict[TTable, int]): topological order of the tables.
    _grid_col_heights (Dict[int, int]): current height for each column
      of the slots of the grid.
    _max_width (Dict[int, int]): maximum width of the tables
      for each column of the slots of the grid.
    _vertical_cnt (Dict[int, int]): count of last vertical position of the
      table for each column of slots of the grid.
    _x_coordinates (Dict[int, int]): x_coordinates of each column of slots.
    _y_coordinates (Dict[int, int]): y_coordinates of each row of slots.
  """

  def _table_topological_sort(self) -> None:
    """Method that sorts tables topologically.

    In the topological ordering, sources will always come before the references.
    This implementation of ordering, source will be places as close to its
    references as possible, thus reducing the crossing over of connections.
    """
    queue = deque(self._tables_for_serializing)
    while queue:
      table = queue.popleft()
      for source in table.get_all_sources():
        queue.append(source)
        self._table_order[source] = min(
          self._table_order[source],
          self._table_order[table] - 1
        )

  def _calculate_table_grid_slot_positions(self) -> None:
    """Method that calculates slot positions for each table.

    Relies on topological ordering.
    """
    # tables are sorted in the reverse of topological ordering
    # so the downstream tables will get the position earlier
    for table in sorted(
        self._tables_for_serializing,
        key=lambda t: (-self._table_order[t], t.name)
    ):
      # update the x position, so it would be to the left of all immediate
      # references
      for reference in table.get_all_table_references():
        self._grid_pos[table].x = min(
          self._grid_pos[reference].x - 1,
          self._grid_pos[table].x
        )

      table_height = table.serializing_params.height
      x = self._grid_pos[table].x
      # continue shifting the table to the left until one of the following:
      # table can be added to the column while satisfying height restrictions
      # or an empty column is reached
      while self._vertical_cnt[x] != 0 and self._grid_col_heights[
        x] + table_height > MAX_PIXELS_PER_GRID_COLUMN:
        x = self._grid_pos[table].x = self._grid_pos[table].x - 1

      # table y is the first unused y coordinate for current x
      self._grid_pos[table].y = self._vertical_cnt[x]
      self._grid_pos[table].initialized = True

      # update information for current x
      self._vertical_cnt[x] = self._grid_pos[table].y + 1
      self._grid_col_heights[x] += table_height + TABLE_Y_SPACING
      self._max_width[x] = max(
        self._max_width[x],
        table.serializing_params.width
      )

  def _calculate_table_grid_coordinates(self) -> None:
    """Method that calculates actual coordinates for all tables.

    Method takes into account tables' slot positions, width and height.
    """
    grid_information: Dict[Tuple[int, int]: TTable] = {}
    for table in self._tables_for_serializing:
      grid_pos = self._grid_pos[table]
      if grid_pos.initialized:
        grid_information[grid_pos.to_tuple()] = table
    for x, y in sorted(grid_information.keys()):
      table = grid_information[x, y]
      coord_x, coord_y = 0, 0
      if x - 1 in self._x_coordinates:
        # add _max_width of the last row and spacing
        coord_x = (self._x_coordinates[x - 1] + self._max_width[x - 1] +
                   TABLE_X_SPACING)
      if x in self._y_coordinates:
        coord_y = self._y_coordinates[x]
      table.set_coordinates(Coordinates(coord_x, coord_y))

      if x not in self._x_coordinates:
        self._x_coordinates[x] = coord_x
      self._y_coordinates[x] = (coord_y + table.serializing_params.height
                                + TABLE_Y_SPACING)

  def _center_columns_on_same_y(self) -> None:
    """Centers the columns vertically.

    Each column will have it's center at the same y coordinate """
    current_y_centers = {}
    for x, y in self._y_coordinates.items():
      self._y_coordinates[x] = y - TABLE_Y_SPACING
      current_y_centers[x] = self._y_coordinates[x] / 2
    desired_y_center = max(self._y_coordinates) / 2
    for table in self._tables_for_serializing:
      coord_x, coord_y = table.serializing_params.coordinates.to_tuple()
      x, y = self._grid_pos[table].to_tuple()
      coord_y += (desired_y_center - current_y_centers[x])
      table.set_coordinates(Coordinates(coord_x, coord_y))

  def __init__(self, tables_for_serializing: List[TTable]) -> None:
    self._tables_for_serializing = tables_for_serializing
    self._grid_pos: Dict[TTable, TCoordinates] = defaultdict(lambda:
                                                             Coordinates(0, 0))
    self._table_order: Dict[TTable, int] = defaultdict(lambda: 0)
    self._grid_col_heights: Dict[int, int] = defaultdict(lambda: 0)
    self._max_width: Dict[int, int] = defaultdict(lambda: 0)
    self._vertical_cnt: Dict[int, int] = defaultdict(lambda: 0)
    self._x_coordinates: Dict[int, int] = defaultdict(lambda: 0)
    self._y_coordinates: Dict[int, int] = defaultdict(lambda: 0)

    if self._tables_for_serializing:
      self._table_topological_sort()
      self._calculate_table_grid_slot_positions()
      self._calculate_table_grid_coordinates()
      self._center_columns_on_same_y()
